The goal of this tutorial is to demonstrate how to use the scheduler for local runs with results table stored in a local .csv file.

## Install stnd

First make sure that `stnd` package is installed in your [Anaconda](https://www.anaconda.com/) environment as mentioned [here](../../README.md#installation).

## Prepare experiment script

Start by creating a script for your experiment. It can be anything - from fitting linear regression to LLM pretraining. For demonstration, we've provided `./experiment.py`, which initializes a tensor (with ones or random values), computes its mean, and logs the result.

### Define demo_experiment function

```python
def demo_experiment(
    experiment_config, logger, processes_to_kill_before_exiting
):
```

The `demo_experiment` function contains all the necessary code for the operations described above. To work with the scheduler, it must accept the following three arguments:

- `experiment_config`: A Python dictionary containing all parameters for the experiment.

- `logger`: An instance of the [Logger](https://github.com/arubique/stnd/blob/main/stnd/utility/logger.py#L243) class used to record outputs in the results table or Weights & Biases (if enabled).

- `processes_to_kill_before_exiting`: A list of processes to terminate after the run (usually optional and can be ignored in most cases).


### Wrap the script with scheduler wrapper

To make `./experiments.py` runnable by our scheduler, the `demo_experiment` function should be wrapped and called like this:

```python
def main():
    prepare_wrapper_for_experiment(check_config_for_demo_experiment)(
        demo_experiment
    )()


if __name__ == "__main__":
    main()
```

The function `prepare_wrapper_for_experiment` takes function `check_config_for_demo_experiment` as input and generates a wrapper for script that takes the `demo_experiment` as an input.

The goal of `check_config_for_demo_experiment` is to perform preliminary validation on the experiment_config dictionary and raise errors if its structure is invalid. You can implement any checks you need — the only constraint is that the function must accept the following arguments:

```python
def check_config_for_demo_experiment(config, config_path, logger):
```

- `config`: same as `experiment_config` for `demo_experiment`.
- `config_path`: path to the yaml file where `experiment_config` was parsed from.
- `logger`: same as for `demo_experiment`.

## Prepare default config

Before running the experiment, you also need to specify a default config file. This file serves as the base configuration, and each run's final arguments will be generated by applying arguments deltas relative to it.

For demonstration, we've provided `./default_config.yml` that specifies `experiment_config` dict used by `experiment.py`:

```yaml
image:
  color: red
  shape:
  - 64
  - 64
initialization_type: <will be specified by deltas>
logging:
  use_wandb: false
params:
  random_seed: 42
```

The `use_wandb` field in `logging` dict and `random_seed` in `params` dict are inherent to the scheduler and can be configured no matter which contents `experiment.py` has. Their meanings are explained in the [reference file](../reference/REFERENCE.md).

In contrast, fields like `initialization_type` and the contents of the `image` dict are specific to`experiments.py` and used to parameterize the experiments in this tutorial. `initialization_type` will vary between runs, while the image fields will remain constant across all experiments.

## Prepare results table

Once `experiments.py` and `default_config.yml` are ready, you can create a results table template to store all experiments.

For demonstration, we've provided `./results.csv`, which will store each experiment's configuration parameters and results.

| path_to_default_config | path_to_main | whether_to_run | delta:initialization_type | delta:image/color |
|------------------------|--------------|----------------|---------------------------|-------------------|
| ./tutorials/quick_start_guide/default_config.yml  | ./experiment.py | 1 | zeros | red |
| ./tutorials/quick_start_guide/default_config.yml  | ./experiment.py | 1 | random | orange |
| ./tutorials/quick_start_guide/default_config.yml  | ./experiment.py | 1 | ones | green |

Each experiment is defined in a separate row. For each row, the scheduler uses:

- `path_to_default_config`: path to the base configuration file (e.g., `default_config.yml`)
- `path_to_main`: path to the main experiment script (e.g., `experiments.py`)
- `whether_to_run`: if it is non-zero then experiment will be run, otherwise this line will be ignored by scheduler.
- **Deltas**: Overrides to the default config that define argument values for the run. Column names must start with the `delta:` prefix. For nested config fields, use `/` to separate levels (e.g., `delta:image/color`).

Each row in the table corresponds to running `experiments.py` with a different parameter configuration — for example, `initialization_type == zeros` and `image/color == red` for row 1, and `initialization_type == ones` and `image/color == red` for row 3. These parameters are for demonstration purposes only and are designed to alter the script’s output. All other parameters are shared across experiments and defined in `default_config.yml`.

## Run experiment

Once the results table `results.csv` is filled in, you're ready to run the experiments.

Substitute `<your env>` with the environment where `stnd` is installed (e.g. the one created by [this script](../../prepare_repo.sh)), and `<repo with experiments>` with the path to the repository containing your experiment script (e.g., `experiment.py` in this case, so you should use path to `stnd` repo now).

The scheduler will:

- Create an `experiments/` folder in the specified repo root to store experiment logs.
- Create an `experiment_configs/` folder in the specified repo root to store the generated `.yml` config files corresponding to each run.
- Use the repo in `$PROJECT_ROOT_PROVIDED_FOR_STUNED` to infer the current Git commit and compute code diffs for each run.

Then, run the following command:

```
export ENV=<your env> && export PROJECT_ROOT_PROVIDED_FOR_STUNED=<repo with experiments> && conda activate $ENV && python -m stnd.run_from_csv.__main__ --csv_path $PROJECT_ROOT_PROVIDED_FOR_STUNED/tutorials/quick_start_guide/results.csv --run_locally --conda_env $ENV
```

- `--csv_path`: Path to the results table. If it is relative, then it will be computed relatively to $PROJECT_ROOT_PROVIDED_FOR_STUNED.
- `--run_locally`: Runs the experiments on the local machine without requesting cluster nodes.
  To run experiments on a cluster, see the [cluster guide](../cluster/CLUSTER.md).
- `--conda_env`: Anaconda env to use when running the experiment.py.

The scheduler modifies `results.csv` in-place, and the updated table will look like `filled_results.csv` with all added columns and logged values:

| path_to_default_config | path_to_main | whether_to_run | delta:initialization_type | delta:image/color | status | run_folder | job id | mean of latest tensor | walltime |
|------------------------|--------------|----------------|---------------------------|-------------------|--------|------------|--------|---------------------|----------|
| ./tutorials/quick_start_guide/default_config.yml | ./tutorials/quick_start_guide/experiment.py | 0 | zeros | red | Completed | /Users/arubique/github/stnd/experiments/quick_start_guide/2025-06-22_18:28:51.947154---0ebbd0874dd795a191da---91272 | Not found | 0.0 | 0:00:00.306933 |
| ./tutorials/quick_start_guide/default_config.yml | ./tutorials/quick_start_guide/experiment.py | 1 | random | orange | Fail | /Users/arubique/github/stnd/experiments/quick_start_guide/2025-06-22_18:28:51.947164---71d6f31e6ced61f89e58---91274 | Not found | ? | ? |
| ./tutorials/quick_start_guide/default_config.yml | ./tutorials/quick_start_guide/experiment.py | 0 | ones | green | Completed | /Users/arubique/github/stnd/experiments/quick_start_guide/2025-06-22_18:28:51.947159---587a851afa4b16b2a8c9---91273 | Not found | 0.3333333333333333 | 0:00:00.279293 |

After running the experiments, the results table will be updated with the following columns:

- **`status`**: Indicates the status of each experiment —`Completed` for successful runs, and `Fail` for failures (e.g., row 2 fails due to an invalid `image/color` value: `orange`, while only `red`, `blue`, or `green` are supported in `experiments.py`).
- **`whether_to_run`**: Set to `0` for completed experiments and `1` for failed ones, making it easy to rerun only the failed rows after fixing the issue.
- **`run_folder`**: Local path to the folder containing logs for each experiment.
- **`job id`**: Used only for cluster runs. In this tutorial (local run), it shows `not found` and can be ignored.
- **`mean of the latest tensor`**: A custom value logged from the script using
  `try_to_log_in_csv(logger, "mean of latest tensor", mean)` in `experiment.py`.
- **`walltime`**: Total runtime for each successfully completed experiment.

Additionally, a `results.csv.lock` file will be created alongside `results.csv` and `autogenerated` folder alongside `default_config.yml`. The lock file ensures safe concurrent modifications by multiple experiments and the folder contains config files for each run. Purely utility nature of these artifacts is beyond the scope of this guide so they can be ignored.

### Running experiments with wandb integration

You can also log values not only to the `.csv` file but to [Weights & Biases (wandb)](https://wandb.ai/site/) as well. To enable this in your `default_config.yml`, set:

```
logging:
  use_wandb: true
  wandb:
    netrc_path: <path to wandb's .netrc file>
```

The contents of the wandb's `.netrc` file should look like this:

```yaml
machine api.wandb.ai
  login user
  password <your wandb token>
```

And then run the same command with `stnd.run_from_csv.__main__` as in the [Running experiments](#running-experiments) section:

```
export ENV=<your env> && export PROJECT_ROOT_PROVIDED_FOR_STUNED=<repo with experiments> && conda activate $ENV && python -m stnd.run_from_csv.__main__ --csv_path $PROJECT_ROOT_PROVIDED_FOR_STUNED/tutorials/quick_start_guide/results.csv --run_locally --conda_env $ENV
```

Then the results.csv will be modified into `filled_results_wandb.csv`:

| path_to_default_config | path_to_main | whether_to_run | delta:initialization_type | delta:image/color | status | run_folder | job id | WandB url | mean of latest tensor | walltime |
|------------------------|--------------|----------------|---------------------------|-------------------|--------|------------|--------|-----------|---------------------|----------|
| ./tutorials/quick_start_guide/default_config.yml | ./tutorials/quick_start_guide/experiment.py | 0 | zeros | red | Completed | /Users/arubique/github/stnd/experiments/quick_start_guide/2025-06-22_19:05:46.306431---783f182d444e7d81a056---93437 | Not found | https://wandb.ai/suerte412/quick_start_guide/runs/kfsko3ur | 0.0 | 0:00:04.046145 |
| ./tutorials/quick_start_guide/default_config.yml | ./tutorials/quick_start_guide/experiment.py | 1 | random | orange | Fail | /Users/arubique/github/stnd/experiments/quick_start_guide/2025-06-22_19:05:46.306431---ecdcd4cf70e831dd1c91---93438 | Not found | https://wandb.ai/suerte412/quick_start_guide/runs/447kjla3 | ? | ? |
| ./tutorials/quick_start_guide/default_config.yml | ./tutorials/quick_start_guide/experiment.py | 0 | ones | green | Completed | /Users/arubique/github/stnd/experiments/quick_start_guide/2025-06-22_19:05:46.306390---7f5ed29a4f3114416ba4---93439 | Not found | https://wandb.ai/suerte412/quick_start_guide/runs/kjo9ynr9 | 0.3333333333333333 | 0:00:04.051272 |

An additional column `WandB url` will be added to the results table, providing direct links to the corresponding Weights & Biases runs for each experiment. You can explore the logged values on the [demo run](https://wandb.ai/suerte412/quick_start_guide/runs/kjo9ynr9) to see how the results are displayed.

Logging to wandb is done inside `experiment.py` using the following command:

```python
try_to_log_in_wandb(
    logger,
    wandb_stats_to_log,
    step=i
)
```

You can log any dictionary with the format `field_name: field_value` to wandb. In the current example, the script logs the value of `mean` 10 times in `experiment.py`:

```python
for i in range(10):
    <compute mean>
    wandb_stats_to_log = {
        "mean": mean,
    }
```
